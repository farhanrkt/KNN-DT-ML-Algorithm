# -*- coding: utf-8 -*-
"""Copy of DT_CLO3_AI.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1D8JXb9IIUz__RLftaPXro3NVUfg95y7E

## **Import Library**
"""

import pandas as pd
import numpy as np
import math
import matplotlib
import csv
from statsmodels.graphics.gofplots import qqplot
from matplotlib import pyplot as plt
from sklearn.model_selection import train_test_split
from sklearn.tree import DecisionTreeClassifier
from sklearn.metrics import accuracy_score

from google.colab import drive
drive.mount('/content/drive')

"""## **Load Data**"""

pd.set_option('display.max_row', 1000)
pd.set_option('display.max_column', 1000)

arrhythmia = "/arrhythmia.data"

df_set = pd.read_csv(arrhythmia, header=None)
df_set

#Validasi dataset kosong atau tidak
if (df_set.empty):
  print("The dataset is empty!")
else:
  print("The dataset is not empty")

arrhythmia_name = "/arrhythmia.names"

with open(arrhythmia_name, "r") as file:
    reader = csv.reader(file)
    for row in reader:
        if len(row) > 0:
            print(row[0])

"""## **Data Exploration**"""

arrhythmia = pd.read_csv("/arrhythmia.data")
arrhythmia.info()

arrhythmia.describe()

arrhythmia.tail()

arrhythmia.head()

arrhythmia.shape

"""## **EDA**"""

arrhythmia_name_excel = '/Arrythmia_names_atribut.xlsx'
output_arrhythmia_name_latest = '/arrhythmia.names'

df_name = pd.read_excel(arrhythmia_name_excel)
df_name

names_content = ''
for index, row in df_name.iterrows():
    names_content += f'@attribute {row["atribut_name"]} {row["tipe_data"]}\n'

with open(output_arrhythmia_name_latest, 'w') as file:
    file.write(names_content)

arrhythmia = "/arrhythmia.data"
arrhythmia_name_fix = "/arrhythmia.names"

df_set = pd.read_csv(arrhythmia, header=None)

with open(arrhythmia_name_fix, "r") as file:
    lines = file.readlines()

atribut_lines = [line.strip() for line in lines if line.startswith("@attribute")]
atribut_info = [line.split() for line in atribut_lines]

atribut_names = [info[1] for info in atribut_info]
atribut_types = [info[2] for info in atribut_info]

df_set.columns = atribut_names
df_set = df_set.astype(dict(zip(atribut_names, atribut_types)))

print(df_set)

df_set_temp = df_set

df_set_temp2 = df_set

#Validasi tipe data dari dataset
for dtype in df_set.dtypes.iteritems():
    print(dtype)

df_set.info()

df_set.describe()

total_rows, total_attributes = df_set.shape
print('Jumlah data:', total_rows)
print("Jumlah atribut:", total_attributes)
df_set.head()

df_set.tail()

unique_class = sorted([i for i in df_set['Diagnosa'].unique()])
unique_class

Data_Object = [i for i in df_set.columns if df_set[i].dtypes == 'O']
Data_Linear = [i for i in df_set.columns if df_set[i].dtypes != "O"]
print(Data_Object)
print(Data_Linear)

df_set = df_set.replace(to_replace="?", value=None)

df_arrhythmia = df_set[('J')]
df_arrhythmia.head()

df_set[Data_Object] = df_set[Data_Object].astype(float)

df_set[Data_Object].dtypes

"""## **Check NaN**"""

#Validasi data cek missing values pada kolom
for i in df_set.columns:
  if df_set[i].isna().sum() > 0:
    print(i, 'Has Missing Values')
  else:
    print(i,  'Has No Missing Values')

missing_val_columns = [i for i in df_set.columns if df_set[i].isna().sum() > 0]
missing_val_columns

Data_Object = [i for i in df_set.columns if df_set[i].dtypes == 'O']
Data_Linear = [i for i in df_set.columns if df_set[i].dtypes != "O"]
print(Data_Linear)
print(Data_Object)

columns_linear_null = [
    kolom for kolom in missing_val_columns if kolom in Data_Linear]

print(columns_linear_null)

print(df_set)

df_set.isnull().sum()

df_set = df_set.fillna(df_set.mean())
print(df_set)

df_set.shape

"""##  **Preprocessing Data**

# **Collect Feature**
"""

col_subnet = [i for i in df_set.columns if i not in [
    'Sex', 'Diagnosa', 'DI_RR_WaveExists', 'DI_DD_RR_WaveExists', 'DI_RP_WaveExists', 'DI_DD_RP_WaveExists', 'DI_RT_WaveExists', 'DI_DD_RT_WaveExists']]

print(col_subnet)

col_float = df_set

for i in df_set.columns:
  if (df_set[i] == 0).all():
    col_float.drop(df_set[i])
    print(len(df_set[i]))

print(col_float)

for i in col_float.columns:
  presentasi_null = (col_float[i]==0).sum()/len(col_float[i])
  if presentasi_null >= 0.05 :
    col_float.drop(columns=[i], inplace = True, axis = 1)

print(col_float)

col_float = col_float.drop('Diagnosa', axis = 1)

print(col_float)

df_new = pd.DataFrame()
data_object = ['Sex', 'Diagnosa', 'DI_RR_WaveExists', 'DI_DD_RR_WaveExists', 'DI_RP_WaveExists', 'DI_DD_RP_WaveExists', 'DI_RT_WaveExists', 'DI_DD_RT_WaveExists']
df_new = df_set_temp2[data_object].copy()

print(df_new)

df_new = df_new.drop(['DI_RR_WaveExists', 'DI_DD_RR_WaveExists', 'DI_RP_WaveExists', 'DI_DD_RP_WaveExists', 'DI_RT_WaveExists', 'DI_DD_RT_WaveExists'], axis=1)

print(df_new)

df_clean = pd.concat([col_float, df_new], axis = 1)

print(df_clean)

df_clean.duplicated(keep=False).sum()

"""## **Check NaN 2**"""

df_clean.isnull().sum()

"""# **Outlier**"""

allColumn = [i for i in df_clean.columns if i not in ["index","Sex","Diagnosa"]]

print(allColumn)

print(len(allColumn))

fig, ax = plt.subplots(nrows=11, ncols=10, figsize=(15, 15))
row = 0
col = 0
for i, kolom in enumerate(allColumn[0:102]):
    if col == 10 and row < 11:
        col = 0
        row += 1

    ax[row][col].boxplot(df_clean[kolom])
    ax[row][col].set_title(kolom)

    col += 1

plt.tight_layout()
plt.show()

"""# **Korelasi**"""

correlation = df_clean.corr().abs().iloc[:-1, -1]

print(correlation)

"""Shuffle Data"""

df_clean = df_clean.sample(452).reset_index(drop=True)
df_clean

"""## **Normalizations**"""

def norm(df_clean):
  df_clean = (df_clean - df_clean.min()) / (df_clean.max()- df_clean.min())
  return df_clean

X = df_clean.drop(columns = [df_clean.columns[-1]])
Y = df_clean[df_clean.columns[-1]]

Y = Y.astype('int')

X = norm(X)

print(X)

X_train,X_test,y_train,y_test = train_test_split(X,Y,test_size=0.3)
print(X_train.shape)
print(y_train.shape)
print(X_test.shape)
print(y_test.shape)

print(y_train)

print(X_train)

"""## **DT MODEL**"""

def decision_tree_algorithm(X,Y):
    model = DecisionTreeClassifier()
    model.fit(X,Y)
    return model

"""## **EVALUATION**"""

model = decision_tree_algorithm(X_train, y_train)
predictions = model.predict(X_test)
print(predictions)

print(len(predictions))

print("Value Accuracy:",round(accuracy_score(y_test,predictions) * 136 , 1),"%")