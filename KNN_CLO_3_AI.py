# -*- coding: utf-8 -*-
"""KNN_CLO3_AI.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1SSn63Cm88Qkt1gvxuxTcq52t7hNejdtj

## **Import Library**
"""

import pandas as pd
import numpy as np
import math
import matplotlib
import csv
from statsmodels.graphics.gofplots import qqplot
from matplotlib import pyplot as plt

from google.colab import drive
drive.mount('/content/drive')

"""## **Load Data**"""

pd.set_option('display.max_row', 1000)
pd.set_option('display.max_column', 1000)

arrhythmia = "drive/MyDrive/CLO3_AI/arrhythmia.data"

df_set = pd.read_csv(arrhythmia, header=None)
df_set

arrhythmia_name = "drive/MyDrive/CLO3_AI/arrhythmia.names"

with open(arrhythmia_name, "r") as file:
    reader = csv.reader(file)
    for row in reader:
        if len(row) > 0:
            print(row[0])

"""## **Data Exploration**"""

arrhythmia = pd.read_csv("/content/drive/MyDrive/CLO3_AI/arrhythmia.data")
arrhythmia.info()

arrhythmia.describe()

arrhythmia.tail()

arrhythmia.head()

arrhythmia.shape

"""## **EDA**"""

arrhythmia_name_excel = '/content/drive/MyDrive/CLO3_AI/arrhythmia.xlsx'
output_arrhythmia_name_latest = '/content/drive/MyDrive/CLO3_AI/arrhythmia.names'

df_name = pd.read_excel(arrhythmia_name_excel)
df_name

names_content = ''
for index, row in df_name.iterrows():
    names_content += f'@attribute {row["atribut_name"]} {row["tipe_data"]}\n'

with open(output_arrhythmia_name_latest, 'w') as file:
    file.write(names_content)

arrhythmia = "drive/MyDrive/CLO3_AI/arrhythmia.data"
arrhythmia_name_fix = "drive/MyDrive/CLO3_AI/arrhythmia.names"

df_set = pd.read_csv(arrhythmia, header=None)

with open(arrhythmia_name_fix, "r") as file:
    lines = file.readlines()

atribut_lines = [line.strip() for line in lines if line.startswith("@attribute")]
atribut_info = [line.split() for line in atribut_lines]

atribut_names = [info[1] for info in atribut_info]
atribut_types = [info[2] for info in atribut_info]

df_set.columns = atribut_names
df_set = df_set.astype(dict(zip(atribut_names, atribut_types)))

print(df_set)

df_set_temp = df_set

df_set_temp2 = df_set

df_set.info()

df_set.describe()

total_rows, total_attributes = df_set.shape
print('Jumlah data:', total_rows)
print("Jumlah atribut:", total_attributes)
df_set.head()

df_set.tail()

unique_class = sorted([i for i in df_set['Diagnosa'].unique()])
unique_class

Data_Object = [i for i in df_set.columns if df_set[i].dtypes == 'O']
Data_Linear = [i for i in df_set.columns if df_set[i].dtypes != "O"]
print(Data_Object)
print(Data_Linear)

df_set = df_set.replace(to_replace="?", value=None)

df_arrhythmia = df_set[('J')]
df_arrhythmia.head()

df_set[Data_Object] = df_set[Data_Object].astype(float)

df_set[Data_Object].dtypes

"""# **Check NaN**


"""

missing_val_columns = [i for i in df_set.columns if df_set[i].isna().sum() > 0]
missing_val_columns

Data_Object = [i for i in df_set.columns if df_set[i].dtypes == 'O']
Data_Linear = [i for i in df_set.columns if df_set[i].dtypes != "O"]
print(Data_Linear)
print(Data_Object)

columns_linear_null = [
    kolom for kolom in missing_val_columns if kolom in Data_Linear]

print(columns_linear_null)

print(df_set)

df_set.isnull().sum()

df_set = df_set.fillna(df_set.mean())
print(df_set)

df_set.shape

"""##  **Preprocessing Data**

# **Collect Features**
"""

col_subnet = [i for i in df_set.columns if i not in [
    'Sex', 'Diagnosa', 'DI_RR_WaveExists', 'DI_DD_RR_WaveExists', 'DI_RP_WaveExists', 'DI_DD_RP_WaveExists', 'DI_RT_WaveExists', 'DI_DD_RT_WaveExists']]

print(col_subnet)

col_float = df_set

for i in df_set.columns:
  if (df_set[i] == 0).all():
    col_float.drop(df_set[i])
    print(len(df_set[i]))

print(col_float)

for i in col_float.columns:
  var_null_percentage = (col_float[i]==0).sum()/len(col_float[i])
  if var_null_percentage >= 0.05 :
    col_float.drop(columns=[i], inplace = True, axis = 1)

print(col_float)

col_float = col_float.drop('Diagnosa', axis = 1)

print(col_float)

df_new = pd.DataFrame()
data_object = ['Sex', 'Diagnosa', 'DI_RR_WaveExists', 'DI_DD_RR_WaveExists', 'DI_RP_WaveExists', 'DI_DD_RP_WaveExists', 'DI_RT_WaveExists', 'DI_DD_RT_WaveExists']
df_new = df_set_temp2[data_object].copy()

print(df_new)

df_new = df_new.drop(['DI_RR_WaveExists', 'DI_DD_RR_WaveExists', 'DI_RP_WaveExists', 'DI_DD_RP_WaveExists', 'DI_RT_WaveExists', 'DI_DD_RT_WaveExists'], axis=1)

print(df_new)

df_clean = pd.concat([col_float, df_new], axis = 1)

print(df_clean)

df_clean.duplicated(keep=False).sum()

"""# **Check NaN 2**


"""

df_clean.isnull().sum()

"""# **Outlier**"""

allColumn = [i for i in df_clean.columns if i not in ["index","Sex","Diagnosa"]]

print(allColumn)

print(len(allColumn))

fig, ax = plt.subplots(nrows=11, ncols=10, figsize=(15, 15))
row = 0
col = 0
for i, kolom in enumerate(allColumn[0:102]):
    if col == 10 and row < 11:
        col = 0
        row += 1

    ax[row][col].boxplot(df_clean[kolom])
    ax[row][col].set_title(kolom)

    col += 1

plt.tight_layout()
plt.show()

"""# **Korelasi**"""

correlation = df_clean.corr().abs().iloc[:-1, -1]

print(correlation)

df_clean = df_clean.sample(452).reset_index(drop=True)
df_clean

fold1 =(df_clean.iloc[0:150].reset_index(drop=True), df_clean.iloc[150:1150].reset_index(drop=True))
fold2 =(df_clean.iloc[150:300].reset_index(drop=True), pd.concat([df_clean.iloc[0:150], df_clean.iloc[300:]]).reset_index(drop=True))
fold3 =(df_clean.iloc[300:].reset_index(drop=True), df_clean.iloc[0:300].reset_index(drop=True))

fold_test, fold_train = fold2
print(fold_train)

"""## **Normalizations**"""

def norm(df_clean):
  df_clean = (df_clean - df_clean.min()) / (df_clean.max() - df_clean.min())
  return df_clean

X = df_clean.drop(columns = [df_clean.columns[-1]])
Y = df_clean[df_clean.columns[-1]]

Y = Y.astype('int')

X = norm(X)

print(X)

"""## **KNN MODEL**"""

def euclidean(x1,x2):
 return np.sqrt(np.sum((x1-x2)**2))

euclidean(X.iloc[0], X.iloc[1])

def knn(X_train, y_train, X_test, k):
  dist = []

  for row in range (X_train.shape[0]):
    dist.append(euclidean(X_train.iloc[row],X_test))

  data_aritmia = X_train.copy()
  data_aritmia['Dist'] = dist

  data_aritmia['kelas'] = y_train

  data_aritmia = data_aritmia.sort_values(by= 'Dist').reset_index(drop=True)

  y_pred = data_aritmia.iloc[:k].kelas.mode()
  return y_pred[0]

"""## **EVALUATION**"""

def acc(y_pred, y_true):
  true = 0
  for i in range(len(y_pred)):
    if y_pred[i] == y_true[i]:
      true+=1
  return true/len(y_pred)

def evaluate(fold, k):
  fix_test, fix_train = fold
  X_train, Y_train = fix_train.drop('Diagnosa', axis=1), fix_train.Diagnosa
  X_test, Y_test = fix_test.drop('Diagnosa', axis=1), fix_test.Diagnosa
  X_train = norm(X_train)
  X_test = norm(X_test)
  y_preds = []
  for row in range(X_test.shape[0]):
    y_preds.append(knn(X_train, Y_train, X_test.iloc[row],k))
  return(acc(y_preds, Y_test))

#Main Program with k=5
k = 5
accs = []
folds = [fold1, fold2, fold3]
for i in range(len(folds)):
  accs.append(evaluate(folds[i], k))
print(f'Menggunakan k : {k}, dengan rata-rata akurasi : {sum(accs)/3}')

#Main Program with k=10
k = 10
accs = []
folds = [fold1, fold2, fold3]
for i in range(len(folds)):
  accs.append(evaluate(folds[i], k))
print(f'Menggunakan k : {k}, dengan rata-rata akurasi : {sum(accs)/3}')

#Main Program with k=15
k = 15
accs = []
folds = [fold1, fold2, fold3]
for i in range(len(folds)):
  accs.append(evaluate(folds[i], k))
print(f'Menggunakan k : {k}, dengan rata-rata akurasi : {sum(accs)/3}')

#Main Program with k=20
k = 20
accs = []
folds = [fold1, fold2, fold3]
for i in range(len(folds)):
  accs.append(evaluate(folds[i], k))
print(f'Menggunakan k : {k}, dengan rata-rata akurasi : {sum(accs)/3}')
